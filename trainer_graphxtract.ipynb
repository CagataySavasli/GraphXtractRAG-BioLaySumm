{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-09T13:37:02.144708Z",
     "start_time": "2025-05-09T13:36:53.176872Z"
    }
   },
   "source": [
    "from dask.array import optimize\n",
    "from mlflow.models.cli import predict\n",
    "\n",
    "from lib.utility import CaseBuilder, ResultCalculator, MessageFactory, CustomLossFunction\n",
    "from lib.dataloaders import GraphXtractDataset\n",
    "from lib.gemini import GeminiFineTuner, GeminiTester\n",
    "from lib.rag_factories import RAG_Factory\n",
    "from lib.selectors.models.gat_gcn_selector import GATGCNSelector\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.data import Batch, ClusterData\n",
    "from torch.utils.data._utils.collate import default_collate\n",
    "\n",
    "import google.generativeai as genai\n",
    "from google.generativeai import types\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/cagatay/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T13:37:02.157016Z",
     "start_time": "2025-05-09T13:37:02.154137Z"
    }
   },
   "cell_type": "code",
   "source": "genai.configure(api_key=\"AIzaSyC42OyqZc03g56rzaoC4JkDV9dt7TZ49ic\")",
   "id": "10209cdd119b1f16",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T13:37:02.225161Z",
     "start_time": "2025-05-09T13:37:02.223504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_name = \"elife\"\n",
    "rag_strategy = \"graphxtract\"\n",
    "rag_n = 10\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "print(\"RAG Strategy: \", rag_strategy)\n",
    "print(\"RAG N: \", rag_n)"
   ],
   "id": "f5c148cd5dc883fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Strategy:  graphxtract\n",
      "RAG N:  10\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T13:37:02.282346Z",
     "start_time": "2025-05-09T13:37:02.280321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.data import Batch\n",
    "import pandas as pd\n",
    "\n",
    "def collate_fn(batch):\n",
    "    rows, graphs = zip(*batch)  # rows: Tuple[pd.Series]\n",
    "    return rows, Batch.from_data_list(list(graphs))#graphs\n"
   ],
   "id": "3405b20da81e4192",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T13:37:02.386785Z",
     "start_time": "2025-05-09T13:37:02.327380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "case_builder = CaseBuilder(dataset_name=dataset_name,\n",
    "                           rag_strategy=rag_strategy,\n",
    "                           rag_n=rag_n,\n",
    "                           batch_size=batch_size)\n",
    "\n",
    "selector_model = GATGCNSelector()\n",
    "\n",
    "rag_factory = RAG_Factory()\n",
    "# rag_factory.factory.model = selector_model\n",
    "\n",
    "message_factory = MessageFactory()\n",
    "\n",
    "gemini_trainer = GeminiFineTuner()\n",
    "gemini_tester = GeminiTester()\n",
    "\n",
    "result_calculator = ResultCalculator()\n",
    "# loss_function = CustomLossFunction(reward_smoothing_factor=1.0)\n",
    "\n",
    "source_model = case_builder.genai_model_name"
   ],
   "id": "1a63e4093273031e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T13:37:24.905306Z",
     "start_time": "2025-05-09T13:37:02.396259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_train = GraphXtractDataset(source_name=case_builder.dataset_name, split_name='train')\n",
    "dataset_test = GraphXtractDataset(source_name=case_builder.dataset_name, split_name='test')"
   ],
   "id": "40abf291f9b18561",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T13:37:24.916633Z",
     "start_time": "2025-05-09T13:37:24.913976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=batch_size,        # worker başına bir subset ayrılıp __getitem__ paralelleşir\n",
    "    pin_memory=False,      # GPU’ya aktarırken hız\n",
    "    persistent_workers=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=batch_size,\n",
    "    pin_memory=False,      # GPU’ya aktarırken hız\n",
    "    persistent_workers=True,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ],
   "id": "6c292e8045040867",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T13:37:24.973144Z",
     "start_time": "2025-05-09T13:37:24.970097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def devide_batch(graph_batch, logits_batch):\n",
    "    num_graphs = graph_batch.num_graphs         # veya: batch.batch.max().item()+1\n",
    "\n",
    "    # 3) Her grafiğin logit’lerini ayrı bir listeye topla\n",
    "    per_graph_logits = [\n",
    "    logits_batch[graph_batch.batch == i]      # i’nci grafın düğüm logit’leri\n",
    "    for i in range(num_graphs)\n",
    "    ]\n",
    "\n",
    "    return per_graph_logits\n",
    "\n",
    "def answer_checker(clean_answers, labels):\n",
    "    answer_results = []\n",
    "    label_results = []\n",
    "    for answer, label in zip(clean_answers, labels):\n",
    "        if answer != \"\":\n",
    "            answer_results.append(answer)\n",
    "            label_results.append(label)\n",
    "    return answer_results, label_results\n"
   ],
   "id": "c9b7d8a167a9e00e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T13:37:25.020515Z",
     "start_time": "2025-05-09T13:37:25.018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "optimizer = torch.optim.Adam(selector_model.parameters(), lr=1e-4)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ],
   "id": "b6400b0deb236963",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T13:37:25.073629Z",
     "start_time": "2025-05-09T13:37:25.071108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for epoch in range(1, 6, 2):\n",
    "#     # Gemini Fine-Tune\n",
    "#     selector_model.eval()\n",
    "#     train_messages = []\n",
    "#     for train_row_batch, train_graph_batch in tqdm(test_loader, desc=f\"Epoch: {epoch} | Gemini Training Process: \"):\n",
    "#         with torch.no_grad():\n",
    "#             logits_all_batch = selector_model(train_graph_batch)\n",
    "#             logits_batch = devide_batch(train_graph_batch, logits_all_batch)\n",
    "#             selected_sentence_batch = rag_factory(train_row_batch, logits_batch)\n",
    "#             message_batch = message_factory(pd.DataFrame(train_row_batch), selected_sentence_batch)\n",
    "#             train_messages.extend(message_batch)\n",
    "#     gemini_trainer.set_model(source_model)\n",
    "#     gemini_trainer.set_training_data(train_messages)\n",
    "#     gemini_trainer.set_epoch_count(epoch)\n",
    "#     source_model = gemini_trainer.get_fine_tuned_model_name()\n",
    "#\n",
    "#     source_model = 'tunedModels/graphxtract10elife-1re6tcwq1ell'\n",
    "#\n",
    "#     gemini_tester.set_source_model(source_model)\n",
    "#     gemini_tester.update_genai_model()\n",
    "#\n",
    "#     # Selector Train\n",
    "#\n",
    "#     selector_model.train()\n",
    "#     for current_epoch in range(epoch):\n",
    "#         for train_row_batch, train_graph_batch in tqdm(train_loader, desc=f\"Epoch: {current_epoch+1} / {epoch} | Training Process: \"):\n",
    "#\n",
    "#             optimizer.zero_grad()\n",
    "#\n",
    "#             logits_all_batch = selector_model(train_graph_batch)\n",
    "#             logits_batch = devide_batch(train_graph_batch, logits_all_batch)\n",
    "#\n",
    "#             # Create prompt\n",
    "#             rag_result = rag_factory(train_row_batch, logits_batch)\n",
    "#             selected_sentence_batch, selected_log_probs_batch = zip(*rag_result)\n",
    "#             message_batch = message_factory(pd.DataFrame(train_row_batch), selected_sentence_batch)\n",
    "#\n",
    "#             # Get answer form Gemini\n",
    "#             clean_answers, labels = gemini_tester.predict_batch(message_batch)\n",
    "#             clean_answers, labels = answer_checker(clean_answers, labels)\n",
    "#\n",
    "#             # Calculate performance metrics\n",
    "#             reward = result_calculator.reward_function(clean_answers, labels)\n",
    "#             loss = loss_function(selected_log_probs_batch, reward)\n",
    "#             # Update Model\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n"
   ],
   "id": "6a749a1b92798866",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-09T13:37:25.117851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    import mlflow\n",
    "    import mlflow.pytorch\n",
    "except ImportError:\n",
    "    !pip install mlflow\n",
    "    import mlflow\n",
    "    import mlflow.pytorch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# (1) Deney adını ve parametreleri belirleyin:\n",
    "mlflow.set_experiment(\"GraphXtract_Selector_Training\")\n",
    "\n",
    "# (2) Bir run açın:\n",
    "with mlflow.start_run(run_name=\"selector_finetune\"):\n",
    "    # Log hiperparametreler\n",
    "    mlflow.log_param(\"epoch_schedule\", list(range(1, 10, 2)))\n",
    "    mlflow.log_param(\"optimizer\", optimizer.__class__.__name__)\n",
    "    mlflow.log_param(\"learning_rate\", optimizer.defaults.get('lr'))\n",
    "\n",
    "    global_step = 0\n",
    "\n",
    "    # (3) Orijinal loop'unuza MLflow log ekledik:\n",
    "    for epoch in range(1, 10, 2):\n",
    "        source_model = 'tunedModels/graphxtract10elife-1re6tcwq1ell'\n",
    "        gemini_tester.set_source_model(source_model)\n",
    "        gemini_tester.update_genai_model()\n",
    "\n",
    "        selector_model.train()\n",
    "        for current_epoch in range(epoch):\n",
    "            epoch_loss_sum = 0.0\n",
    "            epoch_reward_sum = 0.0\n",
    "            batch_count = 0\n",
    "\n",
    "            for train_row_batch, train_graph_batch in tqdm(\n",
    "                    train_loader,\n",
    "                    desc=f\"[Epoch {epoch} | Sub-epoch {current_epoch+1}] Training\"):\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                logits_all_batch = selector_model(train_graph_batch)\n",
    "                logits_batch = devide_batch(train_graph_batch, logits_all_batch)\n",
    "\n",
    "                # prompt oluşturma\n",
    "                rag_result = rag_factory(train_row_batch, logits_batch)\n",
    "                selected_sentence_batch, selected_log_probs_batch = zip(*rag_result)\n",
    "                message_batch = message_factory(\n",
    "                    pd.DataFrame(train_row_batch),\n",
    "                    selected_sentence_batch)\n",
    "\n",
    "                # Gemini'den cevap al\n",
    "                try:\n",
    "                    clean_answers, labels = gemini_tester.predict_batch(message_batch)\n",
    "                except:\n",
    "                    gemini_tester.update_genai_model()\n",
    "                    clean_answers, labels = gemini_tester.predict_batch(message_batch)\n",
    "\n",
    "                clean_answers, labels = answer_checker(clean_answers, labels)\n",
    "\n",
    "                # reward ve loss\n",
    "                # reward = result_calculator.reward_function(clean_answers, labels)\n",
    "                # loss = loss_function(selected_log_probs_batch, reward)\n",
    "\n",
    "                prediction_embed = genai.embed_content(\n",
    "                                    model=\"models/text-embedding-004\",\n",
    "                                    content=clean_answers)\n",
    "                labels_embed = genai.embed_content(\n",
    "                                model=\"models/text-embedding-004\",\n",
    "                                content=labels)\n",
    "\n",
    "                prediction_embed = torch.tensor(prediction_embed['embedding']).detach().requires_grad_(True)\n",
    "                labels_embed = torch.tensor(labels_embed['embedding'])\n",
    "                loss = loss_function(prediction_embed, labels_embed)\n",
    "\n",
    "\n",
    "                # backward & step\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # (4) Her batch için loss'u kaydet\n",
    "                global_step += 1\n",
    "                mlflow.log_metric(\"train_loss\", loss.item(), step=global_step)\n",
    "                # mlflow.log_metric(\"train_reward\", reward.item(), step=global_step)\n",
    "\n",
    "                epoch_loss_sum += loss.item()\n",
    "                # epoch_reward_sum += reward.item()\n",
    "                batch_count += 1\n",
    "\n",
    "            # (5) Dilerseniz her alt-epoch sonunda ortalama loss'u da log'larsınız\n",
    "            avg_epoch_loss = epoch_loss_sum / batch_count\n",
    "            avg_epoch_reward = epoch_reward_sum / batch_count\n",
    "            mlflow.log_metric(\"avg_epoch_loss\", avg_epoch_loss, step=epoch)\n",
    "            # mlflow.log_metric(\"avg_epoch_reward\", avg_epoch_reward, step=epoch)\n",
    "\n",
    "            # (6) Eğitim bittikten sonra modeli versiyonlayın\n",
    "            mlflow.pytorch.log_model(\n",
    "                selector_model,\n",
    "                artifact_path=\"selector_model\",\n",
    "                registered_model_name=\"GraphXtractSelector\"\n",
    "            )"
   ],
   "id": "6b7611a5960c6e5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 1 | Sub-epoch 1] Training:   6%|▌         | 16/289 [03:44<34:51,  7.66s/it]  "
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prediction_embed = genai.embed_content(\n",
    "                                    model=\"models/text-embedding-004\",\n",
    "                                    content=clean_answers)"
   ],
   "id": "56e6048234ef21eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7b8a0ca7b9034ce7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
