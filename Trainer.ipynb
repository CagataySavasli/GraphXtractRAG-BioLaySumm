{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from datasets import DatasetDict, Dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from src.RAG_Calculater import RAG\n",
    "from src.Prompt_Factory import prompt_factory\n",
    "from src.Case_Builder import (device,\n",
    "                              bert_version,\n",
    "                              bert_model_name,\n",
    "                              genai_model_name,\n",
    "                              prompt_strategy_used,\n",
    "                              dataset_name\n",
    "                              )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_train = pd.read_json(f'src/dataset/clean/{dataset_name}/{bert_version}_train.json')\n",
    "data_val = pd.read_json(f'src/dataset/clean/{dataset_name}/{bert_version}_validation.json')\n",
    "data_test = pd.read_json(f'src/dataset/clean/{dataset_name}/{bert_version}_test.json')"
   ],
   "id": "d8247cf4186b8fc5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_train['rag_sentences'] = data_train['sentences_similarity'].apply(RAG)\n",
    "data_val['rag_sentences'] = data_val['sentences_similarity'].apply(RAG)\n",
    "data_test['rag_sentences'] = data_test['sentences_similarity'].apply(RAG)"
   ],
   "id": "7d518013220722d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(data_train),\n",
    "    \"validation\": Dataset.from_pandas(data_val),\n",
    "    \"test\": Dataset.from_pandas(data_test)\n",
    "})"
   ],
   "id": "27d644a4dbafacd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,  # Reduced rank\n",
    "    lora_alpha=8,  # Lower scaling factor\n",
    "    #target_modules=[\"q\"],  # Update fewer modules (e.g., only query weights)\n",
    "    lora_dropout=0.1,  # Increased dropout for better regularization\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM  # Task type remains the same\n",
    ")"
   ],
   "id": "3a5d12a2a8a4c2fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(genai_model_name, torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(genai_model_name)"
   ],
   "id": "e0b2dfb91d4f6f0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ],
   "id": "9f466f2e2f8ce595",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n"
   ],
   "id": "10db5795986a6c4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(print_number_of_trainable_model_parameters(model))",
   "id": "5b04330f7f285d3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "peft_model = get_peft_model(model, lora_config)",
   "id": "b213d957056f1204",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(print_number_of_trainable_model_parameters(peft_model))",
   "id": "ebfca73b3f87b293",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for x in data_train['summary']:\n",
    "    print(len(\" \".join(x).split()))"
   ],
   "id": "50caf4f7a56da0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def tokenize_function(example):\n",
    "    # Lay summary için optimize edilmiş prompt\n",
    "    prompt = prompt_factory(prompt_strategy_used, example)\n",
    "    summary = ' '.join(map(str, example['summary']))\n",
    "\n",
    "    # Girdileri tokenlaştırma\n",
    "    example['input_ids'] = tokenizer(\n",
    "        prompt,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=1024,  # T5-small için maksimum girdi boyutu\n",
    "        return_tensors=\"pt\"\n",
    "    ).input_ids.squeeze(0)\n",
    "\n",
    "    # Çıkışları (lay summary) tokenlaştırma\n",
    "    example['labels'] = tokenizer(\n",
    "        summary,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,  # Lay summary genellikle kısa tutulur\n",
    "        return_tensors=\"pt\"\n",
    "    ).input_ids.squeeze(0)\n",
    "\n",
    "    return example\n"
   ],
   "id": "55f0e9deb613c83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['id', 'year', 'title', 'sections', 'headings', 'abstract', 'summary', 'keywords', 'sentences_similarity', 'rag_sentences'])"
   ],
   "id": "93dfd5d5e593a9da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#tokenized_datasets = tokenized_datasets.filter(lambda example, index: index % 100 == 0, with_indices=True)\n",
    "\n",
    "print(f\"Shapes of the datasets:\")\n",
    "print(f\"Training: {tokenized_datasets['train'].shape}\")\n",
    "print(f\"Validation: {tokenized_datasets['validation'].shape}\")\n",
    "print(f\"Test: {tokenized_datasets['test'].shape}\")\n",
    "print(tokenized_datasets)"
   ],
   "id": "ff83552b1ac00af4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "output_dir = f'./results/BiOzU_{bert_version}_{dataset_name}_{prompt_strategy_used}-training'\n",
    "peft_training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    #auto_find_batch_size=True,\n",
    "    learning_rate=1e-3,\n",
    "    num_train_epochs=1,\n",
    "    logging_steps=1\n",
    "    )\n",
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=peft_training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation']\n",
    "    )"
   ],
   "id": "7fe93aa2bb7c7bb7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "peft_trainer.train()",
   "id": "a108cdf9d99bb636",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "peft_model_path=f\"./results/BiOzU_{bert_version}_{dataset_name}_{prompt_strategy_used}-checkpoint-local\"\n",
    "peft_trainer.model.save_pretrained(peft_model_path)\n",
    "tokenizer.save_pretrained(peft_model_path)"
   ],
   "id": "d093ebaf8d2852c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c6e0f372d91a1e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
