{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-06T18:06:21.719954Z",
     "start_time": "2024-12-06T18:06:19.914749Z"
    }
   },
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from src.RAG_Calculater import RAG, get_top_n_articles\n",
    "from src.Massege_Factory import massage_factory\n",
    "from src.Case_Builder import (device,\n",
    "                              bert_version,\n",
    "                              bert_model_name,\n",
    "                              genai_version,\n",
    "                              genai_model_name,\n",
    "                              prompt_strategy_used,\n",
    "                              dataset_name,\n",
    "                              massage_strategy\n",
    "                              )"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:06:32.448041Z",
     "start_time": "2024-12-06T18:06:21.722987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_train = pd.read_json(f'src/dataset/clean/{dataset_name}/{bert_version}_train.json')\n",
    "data_val = pd.read_json(f'src/dataset/clean/{dataset_name}/{bert_version}_validation.json')\n",
    "data_test = pd.read_json(f'src/dataset/clean/{dataset_name}/{bert_version}_test.json')"
   ],
   "id": "72417f6f81497b60",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:06:35.644948Z",
     "start_time": "2024-12-06T18:06:32.950114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_train['rag_sentences'] = data_train['sentences_similarity'].apply(RAG)\n",
    "data_val['rag_sentences'] = data_val['sentences_similarity'].apply(RAG)\n",
    "data_test['rag_sentences'] = data_test['sentences_similarity'].apply(RAG)"
   ],
   "id": "d0a6a797ab7010df",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:06:38.242920Z",
     "start_time": "2024-12-06T18:06:36.074233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(genai_model_name, \n",
    "                                              torch_dtype=torch.bfloat16,\n",
    "                                              low_cpu_mem_usage=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(genai_model_name)"
   ],
   "id": "dcb2b90c98928482",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:06:38.685489Z",
     "start_time": "2024-12-06T18:06:38.678964Z"
    }
   },
   "cell_type": "code",
   "source": "model.eval()",
   "id": "54b3bfcf817f2443",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T18:06:41.200271Z",
     "start_time": "2024-12-06T18:06:39.114461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chatbot = pipeline(\"text-generation\", model=\"BioMistral/BioMistral-7B\", max_new_tokens=512, repetition_penalty=1.2, no_repeat_ngram_size=3)\n",
    "\n",
    "results = []\n",
    "summaries = []"
   ],
   "id": "eace6d209e6e7417",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-06T18:06:41.644555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for idx in range(len(data_test)):\n",
    "    print(f\"\\n {idx+1} / {len(data_test)}\", end=\"\")\n",
    "    \n",
    "    target_row = data_test.loc[idx]\n",
    "    \n",
    "    if massage_strategy == \"few_shot\": \n",
    "        ref_rows_indexes = get_top_n_articles(data_train['title_embedding'], target_row['title_embedding'], n=3)\n",
    "        ref_rows = data_train.loc[ref_rows_indexes].reset_index(drop=True)\n",
    "        \n",
    "    else: \n",
    "        ref_rows = None\n",
    "    \n",
    "    massage = massage_factory(massage_strategy, target_row, ref_rows)\n",
    "    summary = \" \".join(data_test.loc[idx, 'summary'])\n",
    "    \n",
    "    answer = chatbot(massage)[0]['generated_text'][-1]['content']\n",
    "    \n",
    "    results.append(answer)\n",
    "    summaries.append(summary)\n",
    "    "
   ],
   "id": "a503d57267ca70d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1 / 241"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2 / 241"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_results = pd.DataFrame({\n",
    "    'reference': summaries,\n",
    "    'prediction': results\n",
    "})"
   ],
   "id": "b8a2bb7ae814e064",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model_results.to_csv(f'results/{genai_version}_{massage_strategy}_summaries_{bert_version}_{dataset_name}_{prompt_strategy_used}.csv', index=False)",
   "id": "a4fd04cde5537059",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d44645d138df9a34",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
